# CVPR-2025-Papers
## 会议时间：
## 会议网址：
## ❣❣❣ CVPR 2025 论文分类整理ing

## 查看2024年综述文献点这里↘️[2024-CV-Surveys](https://github.com/52CV/CV-Surveys)

## 2025 年论文分类汇总戳这里
↘️[WACV-2025-Papers](https://github.com/52CV/WACV-2025-Papers)
↘️[CVPR-2025-Papers](https://github.com/52CV/CVPR-2025-Papers)


## [2024 年论文分类汇总戳这里](#00000)
## [2023 年论文分类汇总戳这里](#0000)
## [2022 年论文分类汇总戳这里](#000)
## [2021 年论文分类汇总戳这里](#00)
## [2020 年论文分类汇总戳这里](#0)

## 3月11日更新 21 篇，共计 129+21 篇。
* [HumanMM: Global Human Motion Recovery from Multi-shot Videos](http://arxiv.org/abs/2503.07597v1)<br>:star:[code](https://zhangyuhong01.github.io/HumanMM/)
* [SOGS: Second-Order Anchor for Advanced 3D Gaussian Splatting](http://arxiv.org/abs/2503.07476v1)
* [AR-Diffusion: Asynchronous Video Generation with Auto-Regressive Diffusion](http://arxiv.org/abs/2503.07418v1)
* [Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways](http://arxiv.org/abs/2503.07026v1)
* [DirectTriGS: Triplane-based Gaussian Splatting Field Representation for 3D Generation](http://arxiv.org/abs/2503.06900v1)
* [CATANet: Efficient Content-Aware Token Aggregation for Lightweight Image Super-Resolution](http://arxiv.org/abs/2503.06896v1)
* [Interactive Medical Image Analysis with Concept-based Similarity Reasoning](http://arxiv.org/abs/2503.06873v1)<br>:star:[code](https://github.com/tadeephuy/InteractCSR)
* [AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP](http://arxiv.org/abs/2503.06661v1)<br>:star:[code](https://github.com/Mwxinnn/AA-CLIP)
* [Instance-wise Supervision-level Optimization in Active Learning](http://arxiv.org/abs/2503.06517v1)<br>:star:[code](https://github.com/matsuo-shinnosuke/ISOAL)
* [Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning](http://arxiv.org/abs/2503.06457v1)<br>:star:[code](https://github.com/WeiDai-David/2025CVPR_GGEUR)
* [STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification](http://arxiv.org/abs/2503.06277v1)
* [Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection](http://arxiv.org/abs/2503.06237v1)
* [Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices](http://arxiv.org/abs/2503.06063v1)<br>:star:[code](https://github.com/EIT-NLP/Layer_Select_Fuse_for_MLLM)
* [VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation](http://arxiv.org/abs/2503.07135v1)
* [Synchronized Video-to-Audio Generation via Mel Quantization-Continuum Decomposition](http://arxiv.org/abs/2503.06984v1)<br>:star:[code](https://wjc2830.github.io/MelQCD/)
* [GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks](http://arxiv.org/abs/2503.06514v1)
* [Color Alignment in Diffusion](http://arxiv.org/abs/2503.06746v1)
* [LatexBlend: Scaling Multi-concept Customized Generation with Latent Textual Blending](http://arxiv.org/abs/2503.06956v1)
* [A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning](http://arxiv.org/abs/2503.06960v1)<br>:star:[code](https://github.com/CVMI-Lab/SlotMIM)
* [Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning](http://arxiv.org/abs/2503.07591v1)<br>:star:[code](https://bardisafa.github.io/PreSel)
* [PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model](http://arxiv.org/abs/2503.06186v1)

## Feature Matching(‌特征匹配)
* [JamMa: Ultra-lightweight Local Feature Matching with Joint Mamba](http://arxiv.org/abs/2503.03437v1)<br>:star:[code](https://leoluxxx.github.io/JamMa-page/)

## Neural Radiance Fields
* [RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo-Embeddings](http://arxiv.org/abs/2502.19781v1)
* 渲染
  * [Differentiable Inverse Rendering with Interpretable Basis BRDFs](https://arxiv.org/abs/2411.17994)
* 4D 
  * [4Deform: Neural Surface Deformation for Robust Shape Interpolation](http://arxiv.org/abs/2502.20208v1)
  * [Dynamic Neural Surfaces for Elastic 4D Shape Representation and Analysis](http://arxiv.org/abs/2503.03132v1)<br>:star:[code](https://4d-dsns.github.io/DSNS/)

## Anomaly Detection(异常检测)
* [One-for-More: Continual Diffusion Model for Anomaly Detection](http://arxiv.org/abs/2502.19848v1)<br>:star:[code](https://github.com/FuNz-0/One-for-More)
* [AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP](http://arxiv.org/abs/2503.06661v1)<br>:star:[code](https://github.com/Mwxinnn/AA-CLIP)
* [Exploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detection](http://arxiv.org/abs/2503.02424v1)<br>:star:[code](https://github.com/luow23/INP-Former)
* [Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection](http://arxiv.org/abs/2503.03562v1)
* [Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection](http://arxiv.org/abs/2502.20981v1)
* OOD
  * [CADRef: Robust Out-of-Distribution Detection via Class-Aware Decoupled Relative Feature Leveraging](http://arxiv.org/abs/2503.00325v1)

## sound
* [Synchronized Video-to-Audio Generation via Mel Quantization-Continuum Decomposition](http://arxiv.org/abs/2503.06984v1)<br>:star:[code](https://wjc2830.github.io/MelQCD/)

## Counting(计数)
* [T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting](http://arxiv.org/abs/2502.20625v1)<br>:star:[code](https://github.com/cha15yq/T2ICount)
* [AirRoom: Objects Matter in Room Reidentification](http://arxiv.org/abs/2503.01130v1)

## Few/Zero-Shot Learning/DG/A(小/零样本/域泛化/域适应)
* [Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection](http://arxiv.org/abs/2503.02101v1)<br>:star:[code](https://github.com/heboyong/Generalized-Diffusion-Detector)

## Vision Transformers
* [Split Adaptation for Pre-trained Vision Transformers](http://arxiv.org/abs/2503.00441v1)<br>:star:[code](https://github.com/conditionWang/Split_Adaptation)
* [BHViT: Binarized Hybrid Vision Transformer](http://arxiv.org/abs/2503.02394v1)
* [Spiking Transformer:Introducing Accurate Addition-Only Spiking Self-Attention for Transformer](http://arxiv.org/abs/2503.00226v1)

## Dataset/Benchmark(数据集/基准)
* 数据集
  * [HarmonySet: A Comprehensive Dataset for Understanding Video-Music Semantic Alignment and Temporal Synchronization](http://arxiv.org/abs/2503.01725v1)<br>:star:[code](https://harmonyset.github.io/)


## 虚拟头像

## Vision-Language
* [Synthetic Data is an Elegant GIFT for Continual Vision-Language Models](http://arxiv.org/abs/2503.04229v1)
* [Words or Vision: Do Vision-Language Models Have Blind Faith in Text?](http://arxiv.org/abs/2503.02199v1)
* [MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations](http://arxiv.org/abs/2503.01019v1)
* [Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval](http://arxiv.org/abs/2503.01980v1)<br>:star:[code](https://github.com/aimagelab/ReT)
* [GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks](http://arxiv.org/abs/2503.06514v1)
* MLLM 
  * [AesthetiQ: Enhancing Graphic Layout Design via Aesthetic-Aware Preference Alignment of Multi-modal Large Language Models](http://arxiv.org/abs/2503.00591v1)
  * [Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices](http://arxiv.org/abs/2503.06063v1)<br>:star:[code](https://github.com/EIT-NLP/Layer_Select_Fuse_for_MLLM)

## Self-Supervised(监督)

## MC/KD/Pruning(模型压缩/知识蒸馏/剪枝)
* [Temporal Separation with Entropy Regularization for Knowledge Distillation in Spiking Neural Networks](http://arxiv.org/abs/2503.03144v1)

## Machine learning(机器学习)
* 联邦学习
  * [Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning](http://arxiv.org/abs/2503.06457v1)<br>:star:[code](https://github.com/WeiDai-David/2025CVPR_GGEUR)
* 主动学习
  * [Instance-wise Supervision-level Optimization in Active Learning](http://arxiv.org/abs/2503.06517v1)<br>:star:[code](https://github.com/matsuo-shinnosuke/ISOAL)
* 类增量学习
  * [Task-Agnostic Guided Feature Expansion for Class-Incremental Learning](http://arxiv.org/abs/2503.00823v1)<br>:star:[code](https://github.com/bwnzheng/TagFex_CVPR2025)
* 对抗
  * [GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs](http://arxiv.org/abs/2411.14133v1)
  * [CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP](http://arxiv.org/abs/2503.03613v1)<br>:star:[code](https://github.com/Sxing2/CLIP-Test-time-Counterattacks)
  * [Towards Effective and Sparse Adversarial Attack on Spiking Neural Networks via Breaking Invisible Surrogate Gradients](http://arxiv.org/abs/2503.03272v1)<br>:star:[code](https://github.com/ryime/PDSG-SDA)

## 机器人导航/SLAM
* 机器人
  * [VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation](http://arxiv.org/abs/2503.07135v1)
* 地点/位置识别
  * [ForestLPR: LiDAR Place Recognition in Forests Attentioning Multiple BEV Density Images](http://arxiv.org/abs/2503.04475v1)

## Scene Flow Estimation(场景流估计)
* [Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation](http://arxiv.org/abs/2503.04718v1)

## Scene Graph Generation(场景图生成)
* [Unbiased Video Scene Graph Generation via Visual and Semantic Dual Debiasing](http://arxiv.org/abs/2503.00548v1)

## Style Transfer(风格迁移)
* [SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary Semantic Style Transfer](http://arxiv.org/abs/2503.04119v1)

## GAN/Image Synthesis(图像生成)
* 三维生成
  * [DirectTriGS: Triplane-based Gaussian Splatting Field Representation for 3D Generation](http://arxiv.org/abs/2503.06900v1)
  * [Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion Pathways](http://arxiv.org/abs/2503.07026v1)
* 图像生成  
  * [DesignDiffusion: High-Quality Text-to-Design Image Generation with Diffusion Models](http://arxiv.org/abs/2503.01645v1)
* 视频生成
  * [GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control](http://arxiv.org/abs/2503.03751v1)<br>:house:[project](https://research.nvidia.com/labs/toronto-ai/GEN3C/)
  * [AR-Diffusion: Asynchronous Video Generation with Auto-Regressive Diffusion](http://arxiv.org/abs/2503.07418v1)
* 图像-视频
  * [Extrapolating and Decoupling Image-to-Video Generation Models: Motion Modeling is Easier Than You Think](http://arxiv.org/abs/2503.00948v1)

## Video 
* [LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant](http://arxiv.org/abs/2503.03663v1)
* 视频监控
  * [Precise Event Spotting in Sports Videos: Solving Long-Range Dependency and Class Imbalance](http://arxiv.org/abs/2503.00147v1)
* 视频理解
  [* [Adaptive Keyframe Sampling for Long Video Understanding](http://arxiv.org/abs/2502.21271v1)<br>:star:[code](https://github.com/ncTimTang/AKS)]

# 3D(三维重建\三维视觉)
* [CADDreamer: CAD object Generation from Single-view Images](http://arxiv.org/abs/2502.20732v1)
* 3DGS
  * [SOGS: Second-Order Anchor for Advanced 3D Gaussian Splatting](http://arxiv.org/abs/2503.07476v1)
  * [NexusSplats: Efficient 3D Gaussian Splatting in the Wild](http://arxiv.org/abs/2411.14514v1)
  * [S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting](http://arxiv.org/abs/2503.04314v1)
  * [DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting](http://arxiv.org/abs/2503.00746v1)<br>:star:[code](https://dof-gaussian.github.io)
  * [Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D Gaussian Splatting from Sparse Inputs](http://arxiv.org/abs/2503.05082v1)<br>:star:[code](https://zhongyingji.github.io/guidevd-3dgs/)
* 三维重建
  * [M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction](http://arxiv.org/abs/2411.12635v1)
  * [MESC-3D:Mining Effective Semantic Cues for 3D Reconstruction from a Single Image](http://arxiv.org/abs/2502.20861v1)<br>:star:[code](https://github.com/QINGQINGLE/MESC-3D)
  * [MUSt3R: Multi-view Network for Stereo 3D Reconstruction](http://arxiv.org/abs/2503.01661v1)
  * [Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models](http://arxiv.org/abs/2503.01774v1)
  * [FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video](http://arxiv.org/abs/2503.04720v1)<br>:house:[project](https://yuegao.me/FluidNexus)
* 深度补全
  * [SVDC: Consistent Direct Time-of-Flight Video Depth Completion with Frequency Selective Fusion](http://arxiv.org/abs/2503.01257v1)<br>:star:[code](https://github.com/Lan1eve/SVDC)
* 场景理解
  * [Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning](http://arxiv.org/abs/2503.00513v1)<br>:star:[code](https://github.com/hanxunyu/Inst3D-LMM)


## Point Cloud(点云)
* [STAR-Edge: Structure-aware Local Spherical Curve Representation for Thin-walled Edge Extraction from Unstructured Point Clouds](http://arxiv.org/abs/2503.00801v1)
* 点云补全
  * [GenPC: Zero-shot Point Cloud Completion via 3D Generative Priors](http://arxiv.org/abs/2502.19896v1)
  * [Self-Supervised Large Scale Point Cloud Completion for Archaeological Site Restoration](http://arxiv.org/abs/2503.04030v1)

## Visual Question Answering(视觉问答)
* [CL-MoE: Enhancing Multimodal Large Language Model with Dual Momentum Mixture-of-Experts for Continual Visual Question Answering](http://arxiv.org/abs/2503.00413v1)
* 视听问答
  * [Question-Aware Gaussian Experts for Audio-Visual Question Answering](http://arxiv.org/abs/2503.04459v1)<br>:star:[code](https://github.com/AIM-SKKU/QA-TIGER)<br>:star:[code](https://aim-skku.github.io/QA-TIGER/)

## Person Re-id

## Human-Object Interactions(人机交互)
* [InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions](http://arxiv.org/abs/2502.20390v1)<br>:star:[code](https://sirui-xu.github.io/InterMimic/)
* [SGC-Net: Stratified Granular Comparison Network for Open-Vocabulary HOI Detection](http://arxiv.org/abs/2503.00414v1)<br>:star:[code](https://github.com/Phil0212/SGC-Net)

## Human Motion Generation(人体运动生成)
* [StickMotion: Generating 3D Human Motions by Drawing a Stickman](http://arxiv.org/abs/2503.04829v1)
* [SemGeoMo: Dynamic Contextual Human Motion Generation with Semantic and Geometric Guidance](http://arxiv.org/abs/2503.01291v1)<br>:star:[code](https://4dvlab.github.io/project_page/semgeomo/)
* 人体运动恢复
  * [HumanMM: Global Human Motion Recovery from Multi-shot Videos](http://arxiv.org/abs/2503.07597v1)<br>:star:[code](https://zhangyuhong01.github.io/HumanMM/)

## Action Detection(动作检测)

## Human Pose Estimation(姿态估计)
* 人体形状重建
  * [PI-HMR: Towards Robust In-bed Temporal Human Shape Reconstruction with Contact Pressure Sensing](http://arxiv.org/abs/2503.00068v1)
* 手势合成
  * [HOP: Heterogeneous Topology-based Multimodal Entanglement for Co-Speech Gesture Generation](http://arxiv.org/abs/2503.01175v1)<br>:star:[code](https://star-uu-wang.github.io/HOP/)

## Medical Image Progress(医学影响处理)
* [LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging](http://arxiv.org/abs/2502.20985v1)
* CT 去噪
  * [Patient-Level Anatomy Meets Scanning-Level Physics: Personalized Federated Low-Dose CT Denoising Empowered by Large Language Model](http://arxiv.org/abs/2503.00908v1)
* 报告生成
  * [Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation](http://arxiv.org/abs/2502.20056v1)
* 医学图像分割
  * [Enhancing SAM with Efficient Prompting and Preference Optimization for Semi-supervised Medical Image Segmentation](http://arxiv.org/abs/2503.04639v1)
* 医学图像分析
  * [Interactive Medical Image Analysis with Concept-based Similarity Reasoning](http://arxiv.org/abs/2503.06873v1)<br>:star:[code](https://github.com/tadeephuy/InteractCSR)

## Autonomous Driving(自动驾驶)
* [CarPlanner: Consistent Auto-regressive Trajectory Planning for Large-scale Reinforcement Learning in Autonomous Driving](http://arxiv.org/abs/2502.19908v1)
* 车道线检测
  * [Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection](http://arxiv.org/abs/2503.06237v1)
* 轨迹预测
  * [Who Walks With You Matters: Perceiving Social Interactions with Groups for Pedestrian Trajectory Prediction](http://arxiv.org/abs/2412.02395v1)


## Object Tracking(目标跟踪)
* 多目标跟踪
  * [Omnidirectional Multi-Object Tracking](http://arxiv.org/abs/2503.04565v1)<br>:star:[code](https://github.com/xifen523/OmniTrack)

## Object Detection(目标检测)
* [MI-DETR: An Object Detection Model with Multi-time Inquiries Mechanism](http://arxiv.org/abs/2503.01463v1)
* 3D目标检测
  * [Ev-3DOD: Pushing the Temporal Boundaries of 3D Object Detection with Event Cameras](http://arxiv.org/abs/2502.19630v1)<br>:star:[code](https://github.com/mickeykang16/Ev3DOD)

## Image/Video Retrieval
* 文本-视频检索
  * [Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions](http://arxiv.org/abs/2503.05186v1)

## Image Fusion(图像融合)
* [One Model for ALL: Low-Level Task Interaction Is a Key to Task-Agnostic Image Fusion](http://arxiv.org/abs/2502.19854v1)<br>:star:[code](https://github.com/AWCXV/GIFNet)

## Image/video Compression(图像/视频压缩)
* [Good, Cheap, and Fast: Overfitted Image Compression with Wasserstein Distortion](http://arxiv.org/abs/2412.00505v1)
* [Balanced Rate-Distortion Optimization in Learned Image Compression](http://arxiv.org/abs/2502.20161v1)
* [Taming Large Multimodal Agents for Ultra-low Bitrate Semantically Disentangled Image Compression](http://arxiv.org/abs/2503.00399v1)<br>:star:[code](https://github.com/yang-xidian/SEDIC)
* 视频压缩
  * [Towards Practical Real-Time Neural Video Compression](http://arxiv.org/abs/2502.20762v1)<br>:star:[code](https://github.com/microsoft/DCVC)

## Image Classification(图像分类)
* [ProAPO: Progressively Automatic Prompt Optimization for Visual Classification](http://arxiv.org/abs/2502.19844v1)
* [Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning](http://arxiv.org/abs/2502.21130v1)
* [STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification](http://arxiv.org/abs/2503.06277v1)

## Image Super-Resolution(超分辨率)
* [DifIISR: A Diffusion Model with Gradient Guidance for Infrared Image Super-Resolution](http://arxiv.org/abs/2503.01187v1)<br>:star:[code](https://github.com/zirui0625/DifIISR)
* [CATANet: Efficient Content-Aware Token Aggregation for Lightweight Image Super-Resolution](http://arxiv.org/abs/2503.06896v1)
* [Volume Tells: Dual Cycle-Consistent Diffusion for 3D Fluorescence Microscopy De-noising and Super-Resolution](http://arxiv.org/abs/2503.02261v1)

## Image Progress(图像/视频处理)
* 3D修复
  * [IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement](http://arxiv.org/abs/2503.04501v1)<br>:star:[code](https://xinxinzuo2353.github.io/imfine/)
* 图像恢复
  * [Reconciling Stochastic and Deterministic Strategies for Zero-shot Image Restoration using Diffusion Model in Dual](http://arxiv.org/abs/2503.01288v1)
* 去水印
  * [Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal](http://arxiv.org/abs/2502.20924v1)
* 去噪
  * [BEVDiffuser: Plug-and-Play Diffusion Model for BEV Denoising with Ground-Truth Guidance](http://arxiv.org/abs/2502.19694v1)
  * [Denoising Functional Maps: Diffusion Models for Shape Correspondence](http://arxiv.org/abs/2503.01845v1)<br>:star:[code](https://alekseizhuravlev.github.io/denoising-functional-maps/)
  * [Optimizing for the Shortest Path in Denoising Diffusion Model](http://arxiv.org/abs/2503.03265v1)<br>:star:[code](https://github.com/UnicomAI/ShortDF)

## Image Segmentation(图像分割)
* 裂纹分割
  * [SCSegamba: Lightweight Structure-Aware Vision Mamba for Crack Segmentation in Structures](http://arxiv.org/abs/2503.01113v1)<br>:star:[code](https://github.com/Karl1109/SCSegamba)

## Face
* [Zero-Shot Head Swapping in Real-World Scenarios](http://arxiv.org/abs/2503.00861v1)
* [IF-MDM: Implicit Face Motion Diffusion Model for High-Fidelity Realtime Talking Head Generation](http://arxiv.org/abs/2412.04000v1)<br>:house:[project](https://bit.ly/ifmdm_supplementary)
* 假脸识别/检测
  * [Towards General Visual-Linguistic Face Forgery Detection(V2)](http://arxiv.org/abs/2502.20698v1)<br>:star:[code](https://github.com/skJack/VLFFD.git)
* 人脸动画
  * [KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation](http://arxiv.org/abs/2503.01715v1)
* 说话头
  * [InsTaG: Learning Personalized 3D Talking Head from Few-Second Video](http://arxiv.org/abs/2502.20387v1)<br>:star:[code](https://fictionarry.github.io/InsTaG/)

## Othere(其它)
* [One-Step Event-Driven High-Speed Autofocus](http://arxiv.org/abs/2503.01214v1)
* [Color Alignment in Diffusion](http://arxiv.org/abs/2503.06746v1)
* [LatexBlend: Scaling Multi-concept Customized Generation with Latent Textual Blending](http://arxiv.org/abs/2503.06956v1)
* [A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning](http://arxiv.org/abs/2503.06960v1)<br>:star:[code](https://github.com/CVMI-Lab/SlotMIM)
* [Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning](http://arxiv.org/abs/2503.07591v1)<br>:star:[code](https://bardisafa.github.io/PreSel)
* [PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model](http://arxiv.org/abs/2503.06186v1)
* [Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior](http://arxiv.org/abs/2502.21048v1)
* [Entropy Bootstrapping for Weakly Supervised Nuclei Detection](http://arxiv.org/abs/2411.13528v1)
* [EgoLife: Towards Egocentric Life Assistant](http://arxiv.org/abs/2503.03803v1)<br>:star:[code](https://egolife-ai.github.io/)<br>:star:[code](https://github.com/EvolvingLMMs-Lab/EgoLife)
* [Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for Pediatric Left Ventricular Ejection Fraction Regression](http://arxiv.org/abs/2503.04131v1)
* [STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural Networks](http://arxiv.org/abs/2503.02689v1)
* [Voxel-Aggergated Feature Synthesis: Efficient Dense Mapping for Simulated 3D Reasoning](https://arxiv.org/abs/2411.10616)
* [LoyalDiffusion: A Diffusion Model Guarding Against Data Replication](http://arxiv.org/abs/2412.01118v1)
* [Do computer vision foundation models learn the low-level characteristics of the human visual system?](http://arxiv.org/abs/2502.20256v1)
* [V$^2$Dial: Unification of Video and Visual Dialog via Multimodal Experts](http://arxiv.org/abs/2503.02063v1)
* [ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse Points](http://arxiv.org/abs/2503.02745v1)<br>:house:[project](https://vcc.tech/research/2025/ArcPro)
* [h-Edit: Effective and Flexible Diffusion-Based Editing via Doob's h-Transform](http://arxiv.org/abs/2503.02187v1)<br>:star:[code](https://github.com/nktoan/h-edit)
* [Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content](http://arxiv.org/abs/2503.02357v1)<br>:star:[code](https://github.com/zzc-1998/Q-Eval)
* [PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers](http://arxiv.org/abs/2503.02388v1)
* [Attention Distillation: A Unified Approach to Visual Characteristics Transfer](http://arxiv.org/abs/2502.20235v1)<br>:star:[code](https://github.com/xugao97/AttentionDistillation)
* [OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels](http://arxiv.org/abs/2502.20087v1)<br>:star:[code](https://github.com/LMMMEng/OverLoCK)
* [ReCon: Enhancing True Correspondence Discrimination through Relation Consistency for Robust Noisy Correspondence Learning](http://arxiv.org/abs/2502.19962v1)<br>:star:[code](https://github.com/qxzha/ReCon)
* [CLIP Under the Microscope: A Fine-Grained Analysis of Multi-Object Representation](http://arxiv.org/abs/2502.19842v1)<br>:star:[code](https://clip-analysis.github.io)
* [Finding Local Diffusion Schrödinger Bridge using Kolmogorov-Arnold Network](http://arxiv.org/abs/2502.19754v1)<br>:star:[code](https://github.com/Qiu-XY/LDSB)
* [CacheQuant: Comprehensively Accelerated Diffusion Models](http://arxiv.org/abs/2503.01323v1)<br>:star:[code](https://github.com/BienLuky/CacheQuant)
* [Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach](http://arxiv.org/abs/2502.19691v1)<br>:star:[code](https://github.com/chenchenzong/EAOA)
* [Knowledge Bridger: Towards Training-free Missing Multi-modality Completion](http://arxiv.org/abs/2502.19834v1)
* [STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding](http://arxiv.org/abs/2502.20678v1)
* [Dataset Distillation with Neural Characteristic Function: A Minmax Perspective](http://arxiv.org/abs/2502.20653v1)
* [Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical Codebook-Text Alignment with Long Text](http://arxiv.org/abs/2503.01261v1)
* [GenVDM: Generating Vector Displacement Maps From a Single Image](http://arxiv.org/abs/2503.00605v1)
* [Solving Instance Detection from an Open-World Perspective](http://arxiv.org/abs/2503.00359v1)
* [Distilled Prompt Learning for Incomplete Multimodal Survival Prediction](http://arxiv.org/abs/2503.01653v1)<br>:star:[code](https://github.com/Innse/DisPro)
* [Rashomon Sets for Prototypical-Part Networks: Editing Interpretable Models in Real-Time](http://arxiv.org/abs/2503.01087v1)
* [WeGen: A Unified Model for Interactive Multimodal Generation as We Chat](http://arxiv.org/abs/2503.01115v1)<br>:star:[code](https://github.com/hzphzp/WeGen)
* [SpiritSight Agent: Advanced GUI Agent with One Look](http://arxiv.org/abs/2503.03196v1)<br>:house:[project](https://huggingface.co/SenseLLM/SpiritSight-Agent-8B)
* [DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles](http://arxiv.org/abs/2503.03651v1)<br>:star:[code](https://github.com/showlab/DoraCycle)
* [Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization](http://arxiv.org/abs/2503.03519v1)
* [CoSDH: Communication-Efficient Collaborative Perception via Supply-Demand Awareness and Intermediate-Late Hybridization](http://arxiv.org/abs/2503.03430v1)<br>:star:[code](https://github.com/Xu2729/CoSDH)
* [Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers](http://arxiv.org/abs/2503.03307v1)<br>:star:[code](https://github.com/jizhaox/relpose-event)
* [AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning Biased Models with Contextual Synthetic Data](http://arxiv.org/abs/2503.05665v1)<br>:star:[code](https://github.com/zengqunzhao/AIM-Fair)<br>:star:[code](https://zengqunzhao.github.io/AIMFair)
* [Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces](http://arxiv.org/abs/2503.05283v1)
* [DecoupledGaussian: Object-Scene Decoupling for Physics-Based Interaction](http://arxiv.org/abs/2503.05484v1)<br>:star:[code](https://wangmiaowei.github.io/DecoupledGaussian.github.io/)

<a name="0"/>

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers) 
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)

<a name="00"/>

## 2021 年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

<a name="000"/>

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers/blob/main/README.md)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers/blob/main/README.md)

<a name="0000"/>

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)
↘️[ICCV-2023-Papers](https://github.com/52CV/ICCV-2023-Papers)
↘️[2023-CV-Surveys](https://github.com/52CV/CV-Surveys/blob/main/2023-CV-Surveys.md)

<a name="00000"/>

## 2023 年论文分类汇总戳这里
↘️[WACV-2024-Papers](https://github.com/52CV/WACV-2024-Papers)
↘️[CVPR-2024-Papers](https://github.com/52CV/CVPR-2024-Papers)
↘️[ECCV-2024-Papers](https://github.com/52CV/ECCV-2024-Papers)


### 扫码CV君微信(注明：CVPR)入微信交流群：
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)